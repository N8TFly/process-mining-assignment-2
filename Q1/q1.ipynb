{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization: \n",
    "- pip3 install pm4py\n",
    "- do a system wide install of graphviz: https://www.graphviz.org/download/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pm4py\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.visualization.petrinet import visualizer as pn_vis_factory\n",
    "from pm4py.objects.petri.exporter.exporter import pnml as pnml_exporter\n",
    "from graphviz import *\n",
    "\n",
    "# Log Filtering & Statistics\n",
    "from pm4py.algo.filtering.log.cases import case_filter\n",
    "from pm4py.algo.filtering.log.variants import variants_filter\n",
    "from pm4py.statistics.traces.log import case_statistics\n",
    "\n",
    "# Conformance checking\n",
    "from pm4py.evaluation.replay_fitness import evaluator as replay_fitness_evaluator\n",
    "from pm4py.evaluation.precision import evaluator as precision_evaluator\n",
    "from pm4py.evaluation.generalization import evaluator as generalization_evaluator\n",
    "from pm4py.evaluation.simplicity import evaluator as simplicity_evaluator\n",
    "\n",
    "# Alpha Miner\n",
    "from pm4py.algo.discovery.alpha import algorithm as alpha_miner\n",
    "\n",
    "# IMDFb miner\n",
    "from pm4py.algo.discovery.inductive import algorithm as inductive_miner\n",
    "\n",
    "# Heuristics miner\n",
    "from pm4py.algo.discovery.heuristics import algorithm as heuristics_miner\n",
    "\n",
    "import utils  # own module with paths and functions\n",
    "\n",
    "LOAD_REGULAR_LOG = False  # for True, need to run 'prep_data.ipynb' first\n",
    "LOAD_DF = False  # for True, need to run 'prep_data.ipynb' first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_REGULAR_LOG:\n",
    "    log = xes_importer.apply(utils.PATH_LOG)\n",
    "else:\n",
    "    log = utils.load_log()  # < 60 s run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_DF:\n",
    "    df = utils.load_parquet() # < 10 s run\n",
    "    df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Work in progress] Explore and filter log files\n",
    "link: http://pm4py.pads.rwth-aachen.de/documentation/filtering-logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    print(log[0]) #prints the first trace of the log\n",
    "    print(log[0][0]) #prints the first event of the first trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See 'exploration.ipynb' for some explorative analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#traces_total = len(log.traces)\n",
    "variants_count = case_statistics.get_variant_statistics(log)\n",
    "variants_count = sorted(variants_count, key=lambda x: x['count'], reverse=True)\n",
    "# print(variants_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_log = case_filter.filter_on_case_performance(log, 12, 8640000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Apply alpha miner to discover the process model\n",
    "- green node = starting point\n",
    "- orange node = ending point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net, initial_marking, final_marking = alpha_miner.apply(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gviz = pn_vis_factory.apply(net, initial_marking, final_marking)\n",
    "pn_vis_factory.view(gviz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnml_exporter.export_net(net, initial_marking, \"alpha_miner_petri.pnml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conformance check Alpha Miner\n",
    "- Fitness: how much of the behavior that was observed in the event log fits the process model\n",
    "- Precision: how much behavior a process model allows for that was never observed in the event log.\n",
    "- Generalization: how well a process model generalizes to behavior that is possible in the business process but was never observed in the event log\n",
    "- Simplicity: (??) complexity of the model vs simplicity\n",
    "\n",
    "link: https://pm4py.fit.fraunhofer.de/documentation#conformance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "\n",
    "# fitness based on toked-based replay\n",
    "fitness = replay_fitness_evaluator.apply(log, net, initial_marking, final_marking, variant=replay_fitness_evaluator.Variants.TOKEN_BASED)\n",
    "\n",
    "with open(\"alpha_miner_results.txt\", \"w\") as file:\n",
    "    file.write(str(fitness))\n",
    "    file.write(\"\\n\")\n",
    "\n",
    "print(f\"[ Finished writing fitness metric in: {time.perf_counter() - start} sec]\")\n",
    "\n",
    "# collect garbage, will probably fail further functions because the log is loaded in mem\n",
    "gc.collect()\n",
    "\n",
    "# precision based on token-based replay\n",
    "prec = precision_evaluator.apply(log, net, initial_marking, final_marking, variant=precision_evaluator.Variants.ALIGN_ETCONFORMANCE)\n",
    "\n",
    "with open(\"alpha_miner_results.txt\", \"w\") as file:\n",
    "    file.write(str(prec))\n",
    "    file.write(\"\\n\")\n",
    "\n",
    "print(f\"[ Finished Precision metric: {time.perf_counter() - start} sec]\")\n",
    "\n",
    "# collect garbage\n",
    "gc.collect()\n",
    "\n",
    "# generalization based on token-based replay\n",
    "gen = generalization_evaluator.apply(log, net, initial_marking, final_marking)\n",
    "\n",
    "with open(\"alpha_miner_results.txt\", \"w\") as file:\n",
    "    file.write(str(gen))\n",
    "    file.write(\"\\n\")\n",
    "\n",
    "# collect garbage\n",
    "gc.collect()\n",
    "\n",
    "print(f\"[ Finished Generalization metric: {time.perf_counter() - start} sec]\")\n",
    "\n",
    "# simplicity measured by the inverse arc degree\n",
    "simp = simplicity_evaluator.apply(net)\n",
    "\n",
    "with open(\"alpha_miner_results.txt\", \"w\") as file:\n",
    "    file.write(str(simp))\n",
    "    file.write(\"\\n\")\n",
    "print(f\"[Finished: {time.perf_counter() - start}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generalization\n",
    "Basically, a model is general whether the elements of the model are visited enough often during a replay operation (of the log on the model). A model may be perfectly fitting the log and perfectly precise (for example, reporting the traces of the log as sequential models going from the initial marking to the final marking; a choice is operated at the initial marking). \n",
    "\n",
    "#### Simplicity\n",
    "First of all, we consider the average degree for a place/transition of the Petri net, that is defined as the sum of the number of input arcs and output arcs. If all the places have at least one input arc and output arc, the number is at least 2. Choosing a number k between 0 and infinity, the simplicity based on the inverse arc degree is then defined as 1.0 / (1.0 + max(mean_degree - k, 0))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [fitness, prec, gen, simp]\n",
    "with open(\"alpha_miner_results.txt\", \"w\") as file:\n",
    "    for i in range(4):\n",
    "        file.write(str(results[i]))\n",
    "        file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation of Alpha miner conformance check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Inductive Miner Directly Follows algorithm to discover the process model\n",
    "- link: http://pm4py.pads.rwth-aachen.de/documentation/process-discovery/inductive-miner/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net, initial_marking, final_marking = inductive_miner.apply(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gviz = pn_vis_factory.apply(net, initial_marking, final_marking)\n",
    "pn_vis_factory.view(gviz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnml_exporter.export_net(net, initial_marking, \"inductive_miner_petri.pnml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conformance check Inductive Miner Directly Follows algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "\n",
    "# fitness based on toked-based replay\n",
    "fitness = replay_fitness_evaluator.apply(log, net, initial_marking, final_marking, variant=replay_fitness_evaluator.Variants.TOKEN_BASED)\n",
    "\n",
    "print(f\"[ Finished Fitness metric in: {time.perf_counter() - start} sec]\")\n",
    "\n",
    "# precision based on token-based replay\n",
    "prec = precision_evaluator.apply(log, net, initial_marking, final_marking, variant=precision_evaluator.Variants.ETCONFORMANCE_TOKEN)\n",
    "\n",
    "print(f\"[ Finished Precision metric: {time.perf_counter() - start} sec]\")\n",
    "\n",
    "# generalization based on token-based replay\n",
    "gen = generalization_evaluator.apply(log, net, initial_marking, final_marking)\n",
    "\n",
    "print(f\"[ Finished Generalization metric: {time.perf_counter() - start} sec]\")\n",
    "\n",
    "# simplicity measured by the inverse arc degree\n",
    "simp = simplicity_evaluator.apply(net)\n",
    "\n",
    "print(f\"[Finished: {time.perf_counter() - start}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [fitness, prec, gen, simp]\n",
    "with open(\"IMDFa_results.txt\", \"w\") as file:\n",
    "    for i in range(4):\n",
    "        file.write(str(results[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Inductive Miner Directly Follows algorithm to discover the process model\n",
    "- link: http://pm4py.pads.rwth-aachen.de/documentation/process-discovery/inductive-miner/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net, initial_marking, final_marking = heuristics_miner.apply(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gviz = pn_vis_factory.apply(net, initial_marking, final_marking)\n",
    "pn_vis_factory.view(gviz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnml_exporter.export_net(net, initial_marking, \"heuristics_miner_petri.pnml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conformance check Heuristics Miner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "\n",
    "# fitness based on toked-based replay\n",
    "fitness = replay_fitness_evaluator.apply(log, net, initial_marking, final_marking, variant=replay_fitness_evaluator.Variants.TOKEN_BASED)\n",
    "\n",
    "print(f\"[ Finished Fitness metric in: {time.perf_counter() - start} sec]\")\n",
    "\n",
    "# precision based on token-based replay\n",
    "prec = precision_evaluator.apply(log, net, initial_marking, final_marking, variant=precision_evaluator.Variants.ETCONFORMANCE_TOKEN)\n",
    "\n",
    "print(f\"[ Finished Precision metric: {time.perf_counter() - start} sec]\")\n",
    "\n",
    "# generalization based on token-based replay\n",
    "gen = generalization_evaluator.apply(log, net, initial_marking, final_marking)\n",
    "\n",
    "print(f\"[ Finished Generalization metric: {time.perf_counter() - start} sec]\")\n",
    "\n",
    "# simplicity measured by the inverse arc degree\n",
    "simp = simplicity_evaluator.apply(net)\n",
    "\n",
    "print(f\"[Finished: {time.perf_counter() - start}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [fitness, prec, gen, simp]\n",
    "with open(\"heuristics_miner_results.txt\", \"w\") as file:\n",
    "    for i in range(4):\n",
    "        file.write(str(results[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
